172.16.101.42


hostnamectl  set-hostname spark

rpm -ivh jdk-8u201-linux-x64.rpm 


ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys


tar xzvf spark-2.4.4-bin-hadoop2.7.tgz  -C /usr/local/


vim /etc/profile

export SPARK_HOME=/usr/local/spark-2.4.4-bin-hadoop2.7/
export PATH=$SPARK_HOME/bin:$PATH

source  /etc/profile


mkdir -p /usr/local/hadoop-2.7.4/etc/hadoop

scp 172.16.101.41:/usr/local/hadoop-2.7.4/etc/hadoop/*   /usr/local/hadoop-2.7.4/etc/hadoop/


cd /usr/local/spark-2.4.4-bin-hadoop2.7/conf/

cat > spark-env.sh  << EOF
export JAVA_HOME=/usr/java/jdk1.8.0_201-amd64
export SCALA_HOME=/usr/local/scala-2.11.8
HADOOP_CONF_DIR=/usr/local/hadoop-2.7.4/etc/hadoop/
SPARK_MASTER_IP=172.16.101.42
SPARK_MASTER_PORT=7077
SPARK_MASTER_WEBUI_PORT=8080
SPARK_WORKER_CORES=1
SPARK_WORKER_MEMORY=1000m
SPARK_WORKER_PORT=7078
SPARK_WORKER_WEBUI_PORT=8081
SPARK_WORKER_INSTANCES=1
SPARK_LOCAL_IP=172.16.101.42
EOF




cat > slaves << EOF
spark
EOF




cat > spark-defaults.conf << EOF
spark.master spark://spark:7077
EOF





/usr/local/spark-2.4.4-bin-hadoop2.7/sbin/start-master.sh 

web
http://172.16.101.42:8080/




/usr/local/spark-2.4.4-bin-hadoop2.7/sbin/start-slave.sh  spark://spark:7077









